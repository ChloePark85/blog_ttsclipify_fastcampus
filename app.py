import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
import json
import hashlib
import os
from dotenv import load_dotenv
import time
import nltk
from nltk.tokenize import sent_tokenize
import random
import html
import cv2
import numpy as np

st.set_page_config(page_title="ë¸”ë¡œê·¸ AI ìˆí¼ ìƒì„±ê¸°", page_icon="âœ¨")

load_dotenv()
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

def extract_blog_content(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Referer": "https://www.naver.com"
    }

    try:
        res = requests.get(url, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, "html.parser")
    except Exception as e:
        return [], [], [], f"ìš”ì²­ ì‹¤íŒ¨: {e}"

    # ë„¤ì´ë²„ ë¸”ë¡œê·¸ iframe í™•ì¸
    frame_src = None
    frames = soup.find_all("iframe")
    for frame in frames:
        src = frame.get("src", "")
        if "PostView" in src:
            frame_src = "https://blog.naver.com" + src if not src.startswith("http") else src
            break

    # iframeì´ ìˆìœ¼ë©´ iframe ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    if frame_src:
        try:
            res = requests.get(frame_src, headers=headers)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, "html.parser")
        except Exception as e:
            return [], [], [], f"iframe ìš”ì²­ ì‹¤íŒ¨: {e}"

    # ë³¸ë¬¸ ì¶”ì¶œìš© class í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ìµœì‹  ë° êµ¬ë²„ì „ ëª¨ë‘ í¬í•¨)
    container_classes = [
        "se-main-container",
        "se_component_wrap",
        "se-publishArea",
        "post_content",
        "postViewArea",
        "post-view",
        "view",
        "post-content",
        "entry-content",
        "se-module-content"
    ]

    container = None
    for cls in container_classes:
        container = soup.find("div", class_=cls)
        if container:
            break

    # ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš° article íƒœê·¸ë„ í™•ì¸
    if container is None:
        container = soup.find("article")

    # ì—¬ì „íˆ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš° ì˜¤ë¥˜ ë°˜í™˜
    if container is None:
        # ë””ë²„ê¹…ìš© HTML êµ¬ì¡° í™•ì¸
        st.write("HTML êµ¬ì¡° í™•ì¸ (ì²« 500ì):", soup.prettify()[:500])
        return [], [], [], "â— ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸€ì„ ì‹œë„í•´ ë³´ì„¸ìš”."

    # ìˆœì„œëŒ€ë¡œ ì½˜í…ì¸  ì¶”ì¶œ (í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì›ë˜ ìˆœì„œ ìœ ì§€)
    content_elements = []
    
    # ëª¨ë“  í•˜ìœ„ ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ íƒìƒ‰
    for element in container.find_all(recursive=True):
        # í…ìŠ¤íŠ¸ ìš”ì†Œ í™•ì¸
        if element.name in ["p", "span", "div", "h1", "h2", "h3", "h4"]:
            # íŠ¹ì • í´ë˜ìŠ¤ë¥¼ ê°€ì§„ íƒœê·¸ëŠ” ê±´ë„ˆë›°ê¸° (ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ, ë²„íŠ¼ ë“±)
            skip_classes = ["se-module-image", "se_image", "se-func-button", "se-file-button"]
            if element.get("class") and any(cls in element.get("class", []) for cls in skip_classes):
                continue
                
            text = element.get_text().strip()
            # ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ê°€
            if text and len(text) > 5 and not re.match(r'^[\s\d.,:;!?]+$', text):
                # ì¤‘ë³µ í…ìŠ¤íŠ¸ í™•ì¸
                if not any(item['type'] == 'text' and item['content'] == text for item in content_elements):
                    content_elements.append({
                        'type': 'text',
                        'content': text,
                        'position': len(content_elements)
                    })
        
        # ì´ë¯¸ì§€ ìš”ì†Œ í™•ì¸
        elif element.name == "img":
            for attr in ["data-lazy-src", "src", "data-src"]:
                src = element.get(attr)
                if src:
                    # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if src.startswith("//"):
                        src = "https:" + src
                    # httpë¡œ ì‹œì‘í•˜ê³  base64ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                    if src.startswith("http") and not src.startswith("data:"):
                        # ì¤‘ë³µ ì´ë¯¸ì§€ í™•ì¸
                        if not any(item['type'] == 'image' and item['content'] == src for item in content_elements):
                            content_elements.append({
                                'type': 'image',
                                'content': src,
                                'position': len(content_elements)
                            })
                    break
    
    # ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆì—ì„œ ì¶”ê°€ ì´ë¯¸ì§€ ì°¾ê¸° (ìœ„ì—ì„œ ë†“ì¹œ ê²ƒë“¤)
    for img_container in container.find_all(["div"], class_=lambda c: c and any(x in str(c) for x in ["se-module-image", "se-image-container", "se_image", "__se_module_data"])):
        for img in img_container.find_all("img"):
            for attr in ["data-lazy-src", "src", "data-src"]:
                src = img.get(attr)
                if src:
                    if src.startswith("//"):
                        src = "https:" + src
                    if src.startswith("http") and not src.startswith("data:"):
                        # ì¤‘ë³µ ì´ë¯¸ì§€ í™•ì¸
                        if not any(item['type'] == 'image' and item['content'] == src for item in content_elements):
                            content_elements.append({
                                'type': 'image',
                                'content': src,
                                'position': len(content_elements)
                            })
                    break
    
    # í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë¶„ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    texts = [item['content'] for item in content_elements if item['type'] == 'text']
    image_urls = [item['content'] for item in content_elements if item['type'] == 'image']
    
    # ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
    if not texts and not image_urls:
        st.write("HTML êµ¬ì¡° í™•ì¸ (ì²« 500ì):", soup.prettify()[:500])
        return [], [], [], "â— ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    return texts, image_urls, content_elements, None

def download_image(url):
    """ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Referer": "https://blog.naver.com/"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            try:
                img = Image.open(BytesIO(response.content))
                # ì´ë¯¸ì§€ í¬ë§· ë³€í™˜ (PNGë¡œ í†µì¼)
                buffered = BytesIO()
                img.save(buffered, format="PNG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                return f"data:image/png;base64,{img_str}"
            except Exception:
                return None
        else:
            return None
    except Exception:
        return None
    
def main():
    """ë©”ì¸ Streamlit ì•±"""
    st.title("ë¸”ë¡œê·¸ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸")
    st.markdown("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ì„ ì…ë ¥í•˜ë©´ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•´ë“œë¦½ë‹ˆë‹¤!")
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    blog_url = st.text_input(
        "ğŸ“ ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="https://blog.naver.com/example/123456789",
        help="ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ì „ì²´ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    )
    
    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", type="primary"):
        if not blog_url:
            st.error("ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        if "blog.naver.com" not in blog_url:
            st.error("í˜„ì¬ëŠ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ë§Œ ì§€ì›ë©ë‹ˆë‹¤!")
            return
        
        # í¬ë¡¤ë§ ì§„í–‰
        with st.spinner("ë¸”ë¡œê·¸ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            texts, image_urls, content_elements, error = extract_blog_content(blog_url)
        
        if error:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {error}")
            return
        
        if not texts and not image_urls:
            st.warning("ì¶”ì¶œëœ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¸”ë¡œê·¸ ê¸€ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            return
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! í…ìŠ¤íŠ¸ {len(texts)}ê°œ, ì´ë¯¸ì§€ {len(image_urls)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # ì¶”ì¶œëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
            for i, text in enumerate(texts):
                st.write(f"**í…ìŠ¤íŠ¸ {i+1}:**")
                st.write(text)
                st.write("---")  # êµ¬ë¶„ì„ 
        
        with col2:
            st.subheader("ğŸ–¼ï¸ ì¶”ì¶œëœ ì´ë¯¸ì§€")
            for i, img_url in enumerate(image_urls):
                st.write(f"**ì´ë¯¸ì§€ {i+1}:**")
                
                # ì´ë¯¸ì§€ URL í‘œì‹œ
                st.write(f"URL: {img_url}")
                
                # ì´ë¯¸ì§€ ë¡œë”© ì‹œë„
                try:
                    # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì´ë¯¸ì§€ìš© íŠ¹ë³„ í—¤ë”
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                        'Referer': 'https://blog.naver.com/',
                        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
                        'Cache-Control': 'no-cache'
                    }
                    
                    # ì´ë¯¸ì§€ ìš”ì²­
                    response = requests.get(img_url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        # PILë¡œ ì´ë¯¸ì§€ ì—´ê¸°
                        img = Image.open(BytesIO(response.content))
                        st.image(img, width=300, caption=f"ì´ë¯¸ì§€ {i+1}")
                        st.success("âœ… ì´ë¯¸ì§€ ë¡œë”© ì„±ê³µ")
                    else:
                        st.error(f"âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                        # ê·¸ë˜ë„ Streamlit ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                        st.image(img_url, width=300, caption=f"ì´ë¯¸ì§€ {i+1} (ì§ì ‘ ë¡œë”©)")
                        
                except requests.exceptions.RequestException as e:
                    st.error(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
                    # Streamlit ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                    try:
                        st.image(img_url, width=300, caption=f"ì´ë¯¸ì§€ {i+1} (ì§ì ‘ ë¡œë”©)")
                    except:
                        st.error("âŒ ì´ë¯¸ì§€ ë¡œë”© ì™„ì „ ì‹¤íŒ¨")
                        
                except Exception as e:
                    st.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                    # Streamlit ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                    try:
                        st.image(img_url, width=300, caption=f"ì´ë¯¸ì§€ {i+1} (ì§ì ‘ ë¡œë”©)")
                    except:
                        st.error("âŒ ì´ë¯¸ì§€ ë¡œë”© ì™„ì „ ì‹¤íŒ¨")
                
                st.write("---")  # êµ¬ë¶„ì„ 

if __name__ == "__main__":
    main()